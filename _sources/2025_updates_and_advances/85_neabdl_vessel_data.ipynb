{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy-Augment-Batch-DL with Vessel Data\n",
    "\n",
    "This notebook demonstrates how to use the napari-easy-augment-batch-dl plugin to train deep learning models on vessel segmentation data.\n",
    "\n",
    "### Background\n",
    "\n",
    "The easy-augment-batch-dl plugin provides a streamlined workflow for training deep learning models with minimal data. It has panes that allow you to\n",
    "\n",
    "1.  Draw labels\n",
    "2.  Augment labels  \n",
    "3.  Train/predict with different architectures\n",
    "\n",
    "### Semantic vs Instance Segmentation\n",
    "\n",
    "**Semantic Segmentation**: Every pixel gets classified into a category (background, vessel, cell, etc.)\n",
    "**Instance Segmentation**: Individual objects are separated (vessel 1, vessel 2, cell 1, cell 2, etc.)\n",
    "\n",
    "For this vessel example, we'll use semantic segmentation with multiple classes.\n",
    "\n",
    "### Labeling Strategy\n",
    "\n",
    "**Sparse Labeling**:  Not every pixel has to be labeled.  However some background needs to be labeled to differentiate between background pixels and unlabeled pixels.  For example if there were 2 foreground classes use label 1 for background, 2 for \"class 1\", and 3 for \"class 2\".  Unlabeled pixels (0) will be ignored. \n",
    "\n",
    "**Dense Labeling**:  Every foreground pixel needs to be labeled however background does not need to be labeled.  If there were 2 foreground classes, use 1 for \"class 1\", 2 for \"class 2\" and then the remaining pixels (0) will be treated as background. \n",
    "\n",
    "### Augmentation\n",
    "\n",
    "The plugin includes a panel with various augmentation options. Simply check the desired augmentation types (Horizontal Flip, Random Resize, Random Adjust Color, Elastic Deformation, etc.) and click \"**Augment All Images**\" or \"**Augment Single**\" to automatically generate additional training data from your labeled images.\n",
    "\n",
    "### Train and Predict\n",
    "\n",
    "After generating augmented patches, you can train a model. Use the dropdown menu to select your desired architecture (in the screenshot, `Monai UNet` is selected), then click \"**Train Network**\". Once training is complete, you can use your trained model to predict on new images. You also have the option to load a previously trained model if available.\n",
    "\n",
    "The below screenshot shows Napari-Easy-Augment-Batch open with Semantic labels (1 background, 2 barrier, 3 vessel, 4 cell) drawn. \n",
    "\n",
    "![Easy Augment Label Semantic](screenshots/004_easy_augment_labelling.png?v=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and check versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster_geometry not imported.  This is only needed for the ellipsoid rendering in apply_stardist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\pixi\\microsam_cellposesam\\.pixi\\envs\\default\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'segment_everything'\n",
      "napari version 0.6.6\n",
      "numpy version 2.3.4\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "from napari_easy_augment_batch_dl import easy_augment_batch_dl\n",
    "\n",
    "# for trouble shooting print the napari and numpy version. This can give us clues if there are dependency issues\n",
    "print('napari version', napari.__version__)\n",
    "print('numpy version', np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Napari and Easy Augment Batch DL\n",
    "\n",
    "Start Napari, show Easy-Augment-Batch-DL and show the parent directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_2184\\1010478278.py:3: DeprecationWarning: The 'label_only' parameter is deprecated. Please use the 'mode' parameter instead.\n",
      "  batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'segment_everything'\n",
      "Found framework CellPoseInstanceFramework\n",
      "creating new log file\n",
      "2025-11-18 19:25:56,443 [INFO] WRITING LOG OUTPUT TO C:\\Users\\bnort\\.cellpose\\run.log\n",
      "2025-11-18 19:25:56,444 [INFO] \n",
      "cellpose version: \t4.0.7 \n",
      "platform:       \twin32 \n",
      "python version: \t3.11.14 \n",
      "torch version:  \t2.6.0\n",
      "2025-11-18 19:25:56,446 [WARNING] model_type argument is not used in v4.0.1+. Ignoring this argument...\n",
      "2025-11-18 19:25:56,444 [INFO] \n",
      "cellpose version: \t4.0.7 \n",
      "platform:       \twin32 \n",
      "python version: \t3.11.14 \n",
      "torch version:  \t2.6.0\n",
      "2025-11-18 19:25:56,446 [WARNING] model_type argument is not used in v4.0.1+. Ignoring this argument...\n",
      "2025-11-18 19:25:56,665 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2025-11-18 19:25:56,666 [INFO] >>>> using GPU (CUDA)\n",
      "2025-11-18 19:25:56,665 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2025-11-18 19:25:56,666 [INFO] >>>> using GPU (CUDA)\n",
      "2025-11-18 19:25:58,533 [INFO] >>>> loading model C:\\Users\\bnort\\.cellpose\\models\\cpsam\n",
      "2025-11-18 19:25:58,533 [INFO] >>>> loading model C:\\Users\\bnort\\.cellpose\\models\\cpsam\n",
      "Found framework RandomForestFramework\n",
      "Found framework VesselsSemanticFramework\n",
      "Found framework MicroSamInstanceFramework\n",
      "Exception occurred when creating filenames dataset  AsyncGroup.create_array() got an unexpected keyword argument 'object_codec'\n",
      "Error creating ml labels and features: 'filenames'\n",
      "Found framework RandomForestFramework\n",
      "Found framework VesselsSemanticFramework\n",
      "Found framework MicroSamInstanceFramework\n",
      "Exception occurred when creating filenames dataset  AsyncGroup.create_array() got an unexpected keyword argument 'object_codec'\n",
      "Error creating ml labels and features: 'filenames'\n",
      "Error creating ml_labels: 'DeepLearningProject' object has no attribute 'ml_labels'\n",
      "Random Forest ML may not work properly\n",
      "Adding object boxes layer\n",
      "Error creating ml_labels: 'DeepLearningProject' object has no attribute 'ml_labels'\n",
      "Random Forest ML may not work properly\n",
      "Adding object boxes layer\n",
      "Adding predicted object boxes layer\n",
      "Adding predicted object boxes layer\n",
      "Adding label boxes\n",
      "Data changed\n",
      "Data changed\n",
      "Adding object boxes\n",
      "Adding predicted object boxes\n",
      "Setting object box classes\n",
      "Setting predicted object box classes\n",
      "Adding label boxes\n",
      "Data changed\n",
      "Data changed\n",
      "Adding object boxes\n",
      "Adding predicted object boxes\n",
      "Setting object box classes\n",
      "Setting predicted object box classes\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer)\n",
    "\n",
    "viewer.window.add_dock_widget(\n",
    "    batch_dl\n",
    ")\n",
    "\n",
    "parent_path = r'..\\..\\data\\vessel_3D_lightsheet'\n",
    "\n",
    "batch_dl.load_image_directory(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pixi (microsam_cellposesam)",
   "language": "python",
   "name": "microsam_cellposesam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
