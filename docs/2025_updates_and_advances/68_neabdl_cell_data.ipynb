{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy-Augment-Batch-DL with Cell Data\n",
    "\n",
    "This notebook demonstrates how to use the napari-easy-augment-batch-dl plugin to train deep learning models on cell segmentation data.\n",
    "\n",
    "### Background\n",
    "\n",
    "The easy-augment-batch-dl plugin provides a streamlined workflow for training deep learning models with minimal data. It has panes that allow you to\n",
    "\n",
    "1.  Draw labels\n",
    "2.  Augment labels  \n",
    "3.  Train/predict with different architectures\n",
    "\n",
    "### Semantic vs Instance Segmentation\n",
    "\n",
    "**Semantic Segmentation**: Every pixel gets classified into a category (background, vessel, cell, etc.)\n",
    "**Instance Segmentation**: Individual objects are separated (cell 1, cell 2, cell 3, etc.)\n",
    "\n",
    "For this cell example, we'll use instance segmentation to identify individual cells.\n",
    "\n",
    "### Labeling Strategy\n",
    "\n",
    "**Sparse Labeling**:  Not every pixel has to be labeled.  However some background needs to be labeled to differentiate between background pixels and unlabeled pixels.  For example if there were 2 foreground classes use label 1 for background, 2 for \"class 1\", and 3 for \"class 2\".  Unlabeled pixels (0) will be ignored. \n",
    "\n",
    "**Dense Labeling**:  Every foreground pixel needs to be labeled however background does not need to be labeled.  If there were 2 foreground classes, use 1 for \"class 1\", 2 for \"class 2\" and then the remaining pixels (0) will be treated as background. \n",
    "\n",
    "In this example we use dense labeling, as we label every object in the ROI. \n",
    "\n",
    "### Augmentation\n",
    "\n",
    "The plugin includes a panel with various augmentation options. Simply check the desired augmentation types (Horizontal Flip, Random Resize, Random Adjust Color, Elastic Deformation, etc.) and click \"**Augment All Images**\" or \"**Augment Single**\" to automatically generate additional training data from your labeled images.\n",
    "\n",
    "### Train and Predict\n",
    "\n",
    "After generating augmented patches, you can train a model. Use the dropdown menu to select your desired architecture (in the screenshot, `Micro-sam Instance Framework` is selected), then click \"**Train Network**\". Once training is complete, you can use your trained model to predict on new images. You also have the option to load a previously trained model if available.\n",
    "\n",
    "The below screenshot shows Napari-Easy-Augment-Batch open with Instance labels for individual cells drawn. \n",
    "\n",
    "![Easy Augment Label Instance](screenshots/003_easy_augment_labelling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data\n",
    "\n",
    "This notebook uses the ```napari-easy-augment-batch-dl``` widget to explore and label the data.  If we have a model trained we can also predict using that model. \n",
    "\n",
    "Note:  ```napari-easy-augment-batch-dl``` is a useful tool, especially for labelling, but is currently under construction for other uses.  Right now it **may** be best to use it for labelling and inspecting predictions and do other steps of the deep learning workflow (making patches, training) in notebooks.  (of course you are welcome to try the GUI for other steps and report and hiccups (or disasters) that occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster_geometry not imported.  This is only needed for the ellipsoid rendering in apply_stardist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\pixi\\microsam_cellposesam\\.pixi\\envs\\default\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'segment_everything'\n"
     ]
    }
   ],
   "source": [
    "from cellpose import models, io\n",
    "import os\n",
    "import numpy as np\n",
    "import napari\n",
    "from napari_easy_augment_batch_dl import easy_augment_batch_dl\n",
    "from napari_easy_augment_batch_dl.frameworks.micro_sam_instance_framework import MicroSamInstanceFramework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bnort\\AppData\\Local\\Temp\\ipykernel_40528\\3280710511.py:2: DeprecationWarning: The 'label_only' parameter is deprecated. Please use the 'mode' parameter instead.\n",
      "  batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer, label_only = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'segment_everything'\n",
      "Found framework MicroSamInstanceFramework\n",
      "Found framework CellPoseInstanceFramework\n",
      "creating new log file\n",
      "2025-11-18 19:59:58,551 [INFO] WRITING LOG OUTPUT TO C:\\Users\\bnort\\.cellpose\\run.log\n",
      "2025-11-18 19:59:58,552 [INFO] \n",
      "cellpose version: \t4.0.7 \n",
      "platform:       \twin32 \n",
      "python version: \t3.11.14 \n",
      "torch version:  \t2.6.0\n",
      "2025-11-18 19:59:58,553 [WARNING] model_type argument is not used in v4.0.1+. Ignoring this argument...\n",
      "2025-11-18 19:59:58,735 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2025-11-18 19:59:58,737 [INFO] >>>> using GPU (CUDA)\n",
      "2025-11-18 20:00:00,673 [INFO] >>>> loading model C:\\Users\\bnort\\.cellpose\\models\\cpsam\n",
      "Found framework RandomForestFramework\n",
      "Found framework VesselsSemanticFramework\n",
      "Error creating ml labels and features: No Zarr data type found that matches {'name': '|O', 'object_codec_id': 'json2'}\n",
      "Error creating ml_labels: 'DeepLearningProject' object has no attribute 'ml_labels'\n",
      "Random Forest ML may not work properly\n",
      "Adding object boxes layer\n",
      "Adding predicted object boxes layer\n",
      "Adding label boxes\n",
      "Data changed\n",
      "Data changed\n",
      "Adding object boxes\n",
      "Adding predicted object boxes\n",
      "Setting object box classes\n",
      "Setting predicted object box classes\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer, label_only = False)\n",
    "\n",
    "viewer.window.add_dock_widget(\n",
    "    batch_dl\n",
    ")\n",
    "\n",
    "parent_path = r'..\\..\\data\\cells_with_protrusions'\n",
    "model_path = os.path.join(parent_path, 'models', 'checkpoints')\n",
    "framework_type = \"Micro-sam Instance Framework\"\n",
    "batch_dl.load_image_directory(parent_path)\n",
    "model_name = None #\"microsam_nov2025_3.5_vitb\"\n",
    "\n",
    "# optionally set a pretrained model and settings so we can do prediction\n",
    "batch_dl.network_architecture_drop_down.setCurrentText(framework_type)\n",
    "\n",
    "model = batch_dl.deep_learning_project.frameworks[framework_type]\n",
    "\n",
    "if model_name is not None:\n",
    "    model.model_name = model_name\n",
    "\n",
    "widget = batch_dl.deep_learning_widgets[framework_type]\n",
    "widget.sync_with_framework()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pixi (microsam_cellposesam)",
   "language": "python",
   "name": "microsam_cellposesam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
