{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data\n",
    "\n",
    "This notebook uses the ```napari-easy-augment-batch-dl``` widget to explore and label the data.  If we have a model trained we can also predict using that model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bnort\\miniconda3\\envs\\pytorch_and_SAM3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from cellpose import models, io\n",
    "import os\n",
    "import numpy as np\n",
    "import napari\n",
    "from napari_easy_augment_batch_dl import easy_augment_batch_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found class  PytorchSemanticModel\n",
      "found class  CellPoseInstanceModel\n",
      "creating new log file\n",
      "2024-10-21 10:17:01,543 [INFO] WRITING LOG OUTPUT TO C:\\Users\\bnort\\.cellpose\\run.log\n",
      "2024-10-21 10:17:01,544 [INFO] \n",
      "cellpose version: \t3.0.9 \n",
      "platform:       \twin32 \n",
      "python version: \t3.10.14 \n",
      "torch version:  \t2.2.2+cu118\n",
      "found class  MobileSAMModel\n",
      "found class  YoloSAMModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image file is  C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\8220954_10897041.jpg\n",
      "labelsum is  412306\n",
      "(317, 364, 3) (317, 364)\n",
      "8220954_10897041_0\n",
      "C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\input0/8220954_10897041_0.tif\n",
      "C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\ground truth0/8220954_10897041_0.tif\n",
      "C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\input0/8220954_10897041_0.tif\n",
      "C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\ground truth0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deep_learning_project.py (347): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\ground truth0\\8220954_10897041_0.tif is a low contrast image\n",
      "deep_learning_project.py (368): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\annotations\\class_0\\37752018_59910952.tif is a low contrast image\n",
      "deep_learning_project.py (373): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\predictions\\class_0\\37752018_59910952.tif is a low contrast image\n",
      "deep_learning_project.py (368): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\annotations\\class_0\\8220954_10897041.tif is a low contrast image\n",
      "deep_learning_project.py (373): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\predictions\\class_0\\8220954_10897041.tif is a low contrast image\n",
      "deep_learning_project.py (368): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\annotations\\class_0\\6410573_8085113.tif is a low contrast image\n",
      "deep_learning_project.py (373): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\predictions\\class_0\\6410573_8085113.tif is a low contrast image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted file: C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\input0\\8220954_10897041_0.json\n",
      "Deleted file: C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\input0\\8220954_10897041_0.tif\n",
      "Deleted file: C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\ground truth0\\8220954_10897041_0.tif\n",
      "image file is  C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\8220954_10897041.jpg\n",
      "labelsum is  412306\n",
      "(317, 364, 3) (317, 364)\n",
      "8220954_10897041_0\n",
      "C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\input0/8220954_10897041_0.tif\n",
      "C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\ground truth0/8220954_10897041_0.tif\n",
      "C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\input0/8220954_10897041_0.tif\n",
      "C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\ground truth0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deep_learning_project.py (347): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\labels\\ground truth0\\8220954_10897041_0.tif is a low contrast image\n",
      "deep_learning_project.py (368): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\annotations\\class_0\\37752018_59910952.tif is a low contrast image\n",
      "deep_learning_project.py (373): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\predictions\\class_0\\37752018_59910952.tif is a low contrast image\n",
      "deep_learning_project.py (368): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\annotations\\class_0\\8220954_10897041.tif is a low contrast image\n",
      "deep_learning_project.py (373): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\predictions\\class_0\\8220954_10897041.tif is a low contrast image\n",
      "deep_learning_project.py (368): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\annotations\\class_0\\6410573_8085113.tif is a low contrast image\n",
      "deep_learning_project.py (373): C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data\\ladybugs1\\predictions\\class_0\\6410573_8085113.tif is a low contrast image\n"
     ]
    }
   ],
   "source": [
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "batch_dl = easy_augment_batch_dl.NapariEasyAugmentBatchDL(viewer, label_only = False)\n",
    "\n",
    "viewer.window.add_dock_widget(\n",
    "    batch_dl\n",
    ")\n",
    "\n",
    "data_path = r'C:\\Users\\bnort\\work\\ImageJ2022\\tnia\\notebooks-and-napari-widgets-for-dl\\data'\n",
    "parent_path = os.path.join(data_path, 'ladybugs1')\n",
    "model_path = os.path.join(parent_path, 'models')\n",
    "\n",
    "model_name = None #'cellpose_for_protrusions_2'\n",
    "#mod = models.Cellpose(gpu=True, model_type=\"cyto3\")\n",
    "model_type = \"CellPose Instance Model\"\n",
    "batch_dl.load_image_directory(parent_path)\n",
    "\n",
    "\n",
    "if model_name is not None:\n",
    "    batch_dl.network_architecture_drop_down.setCurrentText(model_type)\n",
    "    batch_dl.deep_learning_project.set_pretrained_model(os.path.join(model_path, model_name), model_type)\n",
    "\n",
    "    model = batch_dl.deep_learning_project.models[model_type]\n",
    "    model.prob_thresh = -1\n",
    "    model.flow_thresh = 0.4\n",
    "    model.chan_segment = 2\n",
    "    model.chan2 = 3\n",
    "\n",
    "    widget = batch_dl.param_widgets[model_type]\n",
    "    widget.sync_with_model()\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 65535)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_path =r'D:\\images\\tnia-python-images\\\\imagesc\\\\2024_10_07_cellpose_multi_nuclear'\n",
    "\n",
    "test = io.imread(os.path.join(parent_path, 'Empty_02 - Copy.tif')).astype('uint16')\n",
    "\n",
    "test.min(), test.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_and_SAM3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
